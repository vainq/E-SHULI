const axios=require('axios');const cheerio=require('cheerio');const PastPaper=require('../models/PastPaper');const SRC=[{name:'REB',url:'https://www.reb.rw'},{name:'NESA',url:'https://www.nesa.gov.rw'},{name:'MINEDUC',url:'https://www.mineduc.gov.rw'}];function meta(name){const n=name.replace(/_/g,' ');const y=n.match(/(20\d{2}|19\d{2})/);const year=y?+y[1]:new Date().getFullYear();const s=n.match(/([A-Za-z]+)\s?(Paper\s?\d+)?/);const subject=s?s[1]:'Unknown';return{year,subject,title:n};}async function refreshPastPapers(){let count=0;for(const s of SRC){try{const html=(await axios.get(s.url,{timeout:15000})).data;const $=cheerio.load(html);const links=new Set();$("a[href$='.pdf']").each((_i,el)=>{const href=$(el).attr('href');if(!href)return;const abs=href.startsWith('http')?href:new URL(href,s.url).toString();links.add(abs);});for(const url of links){const file=decodeURIComponent(url.split('/').pop()||'PastPaper.pdf');const m=meta(file);await PastPaper.updateOne({url},{$set:{...m,level:'Secondary',source:s.name,url}},{upsert:true});count++;}}catch(e){console.warn('Past papers scrape failed for',s.url);}}return count;}module.exports=refreshPastPapers;
